{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Step 0 — GPU check & clean start\n",
        "import torch, gc, os, shutil\n",
        "\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "    print(\"VRAM (GB):\", round(torch.cuda.get_device_properties(0).total_memory/1e9, 2))\n",
        "\n",
        "gc.collect()\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# scratch for offload\n",
        "shutil.rmtree(\"/content/offload\", ignore_errors=True)\n",
        "os.makedirs(\"/content/offload\", exist_ok=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJjJLuJ6So2x",
        "outputId": "d37a1f06-0659-42f6-a7e9-f8485e92b64c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "GPU: NVIDIA A100-SXM4-80GB\n",
            "VRAM (GB): 85.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1 — Install libs\n",
        "!pip -q install --upgrade \"transformers>=4.44.0\" \"accelerate>=0.33.0\" \"huggingface_hub>=0.24.0\" bitsandbytes\n",
        "!pip -q install sentencepiece einops requests pandas matplotlib\n"
      ],
      "metadata": {
        "id": "NghT0w3ASo0o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86d63076-db87-4826-9b51-2990940b934c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1.5 — Point to your tunnel & API key (must match your WSL exports)\n",
        "import os\n",
        "\n",
        "# <<< REPLACE these two with your values if they change >>>\n",
        "NG_URL = \" https://century-steering-operate-obtained.trycloudflare.com/run\"  # base URL (NO trailing /run)\n",
        "SPECTRE_API_KEY = \"my-strong-secret-key\"  # must match WSL's export\n",
        "\n",
        "# sanitize & export\n",
        "os.environ[\"NG_URL\"] = NG_URL.strip()\n",
        "os.environ[\"SPECTRE_API_KEY\"] = SPECTRE_API_KEY\n",
        "\n",
        "print(\"NG_URL:\", os.environ[\"NG_URL\"])\n",
        "print(\"SPECTRE_API_KEY set? \", bool(os.environ.get(\"SPECTRE_API_KEY\")))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUM7TszcSoyj",
        "outputId": "200a320c-b7d1-411f-d0d8-a2523b31e24a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NG_URL: https://century-steering-operate-obtained.trycloudflare.com/run\n",
            "SPECTRE_API_KEY set?  True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2 — SKY130 PDK ranges\n",
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class Sky130Preset:\n",
        "    name: str = \"sky130_01v8_core\"\n",
        "    VDD: float = 1.8\n",
        "    Lmin_um: float = 0.18\n",
        "    Lmax_um: float = 2.0\n",
        "    Wn_um_range: tuple = (0.42, 120.0)\n",
        "    Wp_um_range: tuple = (0.42, 180.0)\n",
        "    W2n_um_range: tuple = (0.42, 120.0)\n",
        "    W2p_um_range: tuple = (0.42, 180.0)\n",
        "    Ib_mA_range: tuple = (0.01, 5.00)      # mA\n",
        "    Ccomp_pF_range: tuple = (0.2, 5.0)     # pF\n",
        "    Rz_ohm_range: tuple = (200.0, 5000.0)  # ohm\n",
        "\n",
        "def make_sky130_pdk():\n",
        "    p = Sky130Preset()\n",
        "    return {\n",
        "        \"preset\": p.name,\n",
        "        \"VDD\": p.VDD,\n",
        "        \"vars\": {\n",
        "            \"Wn_um\":     p.Wn_um_range,\n",
        "            \"Wp_um\":     p.Wp_um_range,\n",
        "            \"W2n_um\":    p.W2n_um_range,\n",
        "            \"W2p_um\":    p.W2p_um_range,\n",
        "            \"L_um\":      (p.Lmin_um, p.Lmax_um),\n",
        "            \"Ib_mA\":     p.Ib_mA_range,\n",
        "            \"Ccomp_pF\":  p.Ccomp_pF_range,\n",
        "            \"Rz_ohm\":    p.Rz_ohm_range,\n",
        "        },\n",
        "    }\n",
        "\n",
        "PDK = make_sky130_pdk()\n",
        "\n",
        "def pdk_midpoint(pdk):\n",
        "    return {k: (lo+hi)/2.0 for k,(lo,hi) in pdk[\"vars\"].items()}\n",
        "\n",
        "PDK\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxKwBzi7Sowf",
        "outputId": "26e0fe0c-3654-45ea-cfb9-3103859ebc25"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'preset': 'sky130_01v8_core',\n",
              " 'VDD': 1.8,\n",
              " 'vars': {'Wn_um': (0.42, 120.0),\n",
              "  'Wp_um': (0.42, 180.0),\n",
              "  'W2n_um': (0.42, 120.0),\n",
              "  'W2p_um': (0.42, 180.0),\n",
              "  'L_um': (0.18, 2.0),\n",
              "  'Ib_mA': (0.01, 5.0),\n",
              "  'Ccomp_pF': (0.2, 5.0),\n",
              "  'Rz_ohm': (200.0, 5000.0)}}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3 — Loader\n",
        "import gc, torch, os\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig\n",
        "try:\n",
        "    from transformers import BitsAndBytesConfig\n",
        "except Exception:\n",
        "    BitsAndBytesConfig = None\n",
        "\n",
        "BASE_REPO       = \"openai/gpt-oss-20b\"\n",
        "ACTOR_REVISION  = \"main\"\n",
        "CRITIC_REVISION = \"main\"\n",
        "\n",
        "ROLE_CACHE = {}\n",
        "\n",
        "def _common_kwargs(gpu_gib=11, cpu_gib=48, offload_dir=\"/content/offload\"):\n",
        "    os.makedirs(offload_dir, exist_ok=True)\n",
        "    kw = dict(\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True,\n",
        "        low_cpu_mem_usage=True,\n",
        "        offload_folder=offload_dir,\n",
        "        max_memory={\"cpu\": f\"{cpu_gib}GiB\"},\n",
        "    )\n",
        "    if torch.cuda.is_available():\n",
        "        kw[\"max_memory\"][0] = f\"{gpu_gib}GiB\"\n",
        "    return kw\n",
        "\n",
        "def load_llm_smart(repo_id=BASE_REPO, revision=\"main\", gpu_gib=11, cpu_gib=48, offload_dir=\"/content/offload\"):\n",
        "    tok = AutoTokenizer.from_pretrained(repo_id, revision=revision, use_fast=True, trust_remote_code=True)\n",
        "    if tok.pad_token_id is None:\n",
        "        tok.pad_token_id = tok.eos_token_id\n",
        "\n",
        "    cfg = AutoConfig.from_pretrained(repo_id, revision=revision, trust_remote_code=True)\n",
        "    qcfg = getattr(cfg, \"quantization_config\", None)\n",
        "    kw = _common_kwargs(gpu_gib=gpu_gib, cpu_gib=cpu_gib, offload_dir=offload_dir)\n",
        "\n",
        "    if qcfg is not None:\n",
        "        model = AutoModelForCausalLM.from_pretrained(repo_id, revision=revision, **kw)\n",
        "    else:\n",
        "        if BitsAndBytesConfig is not None:\n",
        "            bnb_q = BitsAndBytesConfig(\n",
        "                load_in_4bit=True,\n",
        "                bnb_4bit_quant_type=\"nf4\",\n",
        "                bnb_4bit_compute_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
        "                bnb_4bit_use_double_quant=True,\n",
        "            )\n",
        "            model = AutoModelForCausalLM.from_pretrained(repo_id, revision=revision, quantization_config=bnb_q, **kw)\n",
        "        else:\n",
        "            model = AutoModelForCausalLM.from_pretrained(\n",
        "                repo_id, revision=revision,\n",
        "                torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
        "                **kw\n",
        "            )\n",
        "    model.eval()\n",
        "    torch.set_grad_enabled(False)\n",
        "    return model, tok\n",
        "\n",
        "def get_shared_llm():\n",
        "    key = (\"shared_llm\", BASE_REPO, ACTOR_REVISION)\n",
        "    if key not in ROLE_CACHE:\n",
        "        ROLE_CACHE[key] = load_llm_smart(BASE_REPO, ACTOR_REVISION)\n",
        "    return ROLE_CACHE[key]\n",
        "\n",
        "def get_fresh_llm(tag=\"fresh_single\"):\n",
        "    key = (tag, BASE_REPO, \"main\")\n",
        "    if key not in ROLE_CACHE:\n",
        "        ROLE_CACHE[key] = load_llm_smart(BASE_REPO, \"main\")\n",
        "    return ROLE_CACHE[key]\n",
        "\n",
        "def free_all_roles():\n",
        "    ROLE_CACHE.clear()\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "4_vbJ322Soub"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4 — Chat helper + JSON extractor\n",
        "import torch, json\n",
        "\n",
        "def chat(model, tok, messages,\n",
        "         max_new_tokens=64, temperature=0.6, top_p=0.9,\n",
        "         greedy=False, max_time=6.0, repetition_penalty=None):\n",
        "    input_ids = tok.apply_chat_template(messages, add_generation_prompt=True,\n",
        "                                        return_tensors=\"pt\").to(model.device)\n",
        "    attention_mask = torch.ones_like(input_ids)  # prevents pad=eos warning\n",
        "\n",
        "    gen_kwargs = dict(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=not greedy,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        pad_token_id=tok.eos_token_id,\n",
        "        max_time=max_time,\n",
        "    )\n",
        "    if repetition_penalty is not None:\n",
        "        gen_kwargs[\"repetition_penalty\"] = repetition_penalty\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(**gen_kwargs)\n",
        "    new_tokens = out[0, input_ids.shape[-1]:]\n",
        "    return tok.decode(new_tokens, skip_special_tokens=True).strip()\n",
        "\n",
        "def find_json_block(text):\n",
        "    s = text.find(\"{\")\n",
        "    if s < 0: raise ValueError(\"No JSON found\")\n",
        "    depth = 0\n",
        "    for i, ch in enumerate(text[s:], s):\n",
        "        if ch == \"{\": depth += 1\n",
        "        elif ch == \"}\":\n",
        "            depth -= 1\n",
        "            if depth == 0:\n",
        "                return json.loads(text[s:i+1])\n",
        "    raise ValueError(\"Unbalanced braces\")\n"
      ],
      "metadata": {
        "id": "u7gSsuzQSosa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5 — Real simulator: ngspicerunner via Cloudflare tunnel\n",
        "import requests, os, math\n",
        "\n",
        "NG_BASE = os.environ[\"NG_URL\"].strip().rstrip(\"/\")\n",
        "SPECTRE_API_KEY = os.environ[\"SPECTRE_API_KEY\"]\n",
        "\n",
        "# final endpoint\n",
        "SPECTRE_URL = NG_BASE if NG_BASE.endswith(\"/run\") else (NG_BASE + \"/run\")\n",
        "print(\"Simulator endpoint:\", SPECTRE_URL)\n",
        "\n",
        "def _finite(x, fallback):\n",
        "    try:\n",
        "        xv = float(x)\n",
        "        if math.isfinite(xv):\n",
        "            return xv\n",
        "    except Exception:\n",
        "        pass\n",
        "    return float(fallback)\n",
        "\n",
        "def simulate_metrics_ng(x: dict) -> dict:\n",
        "    payload = {\n",
        "        \"Wn_um\":   float(x[\"Wn_um\"]),\n",
        "        \"Wp_um\":   float(x[\"Wp_um\"]),\n",
        "        \"W2n_um\":  float(x[\"W2n_um\"]),\n",
        "        \"W2p_um\":  float(x[\"W2p_um\"]),\n",
        "        \"L_um\":    float(x[\"L_um\"]),\n",
        "        \"Ib_mA\":   float(x[\"Ib_mA\"]),\n",
        "        \"Ccomp_pF\":float(x[\"Ccomp_pF\"]),\n",
        "        \"Rz_ohm\":  float(x[\"Rz_ohm\"]),\n",
        "        \"VDD\":     float(PDK[\"VDD\"]),\n",
        "    }\n",
        "    try:\n",
        "        r = requests.post(SPECTRE_URL, json=payload,\n",
        "                          headers={\"x-api-key\": SPECTRE_API_KEY}, timeout=120)\n",
        "        r.raise_for_status()\n",
        "        obj = r.json()\n",
        "    except Exception as e:\n",
        "        # Hard failure: return conservative-but-finite metrics\n",
        "        return {\n",
        "            \"gain_dB\": 0.0, \"ugbw_MHz\": 0.0, \"phase_margin_deg\": 0.0,\n",
        "            \"power_mW\": 1e3, \"aux\": {\"err\":\"http\", \"msg\": str(e)}\n",
        "        }\n",
        "\n",
        "    a0_db = _finite(obj.get(\"a0_db\", 0.0), 0.0)\n",
        "    ughz  = obj.get(\"ugbw_hz\", None)\n",
        "    ugbw  = _finite(ughz/1e6 if ughz is not None else 0.0, 0.0)\n",
        "    pm    = _finite(obj.get(\"phase_margin_deg\", 0.0), 0.0)\n",
        "    pwr   = _finite(obj.get(\"power_mw\", 1e3), 1e3)\n",
        "\n",
        "    # If DC is railed, penalize\n",
        "    if (obj.get(\"bias_ok\") is False) or (obj.get(\"voutp_dc\") in (0.0, 1.8)) or (obj.get(\"voutm_dc\") in (0.0, 1.8)):\n",
        "        a0_db = float(a0_db)\n",
        "        ugbw  = 0.0\n",
        "        pm    = 0.0\n",
        "        pwr   = max(pwr, 1e3)\n",
        "\n",
        "    return {\n",
        "        \"gain_dB\": float(a0_db),\n",
        "        \"ugbw_MHz\": float(ugbw),\n",
        "        \"phase_margin_deg\": float(pm),\n",
        "        \"power_mW\": float(pwr),\n",
        "        \"aux\": {\n",
        "            \"bias_ok\": obj.get(\"bias_ok\"),\n",
        "            \"vbp_dc\": obj.get(\"vbp_dc\"),\n",
        "            \"voutp_dc\": obj.get(\"voutp_dc\"),\n",
        "            \"voutm_dc\": obj.get(\"voutm_dc\"),\n",
        "            \"mode\": obj.get(\"mode\"),\n",
        "        }\n",
        "    }\n",
        "\n",
        "# Optional probe\n",
        "try:\n",
        "    probe = pdk_midpoint(PDK)\n",
        "    m = simulate_metrics_ng({\n",
        "        **probe,\n",
        "        \"W2n_um\": probe[\"W2n_um\"],\n",
        "        \"W2p_um\": probe[\"W2p_um\"],\n",
        "        \"Ccomp_pF\": probe[\"Ccomp_pF\"],\n",
        "        \"Rz_ohm\": probe[\"Rz_ohm\"],\n",
        "    })\n",
        "    print(\"Probe metrics:\", m)\n",
        "except Exception as e:\n",
        "    print(\"Probe failed (OK if server not yet ready):\", repr(e))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnallLx0Soqb",
        "outputId": "d6075be6-b747-473e-b464-41aa9d5600fc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simulator endpoint: https://century-steering-operate-obtained.trycloudflare.com/run\n",
            "Probe metrics: {'gain_dB': -0.0, 'ugbw_MHz': 417.5965506895971, 'phase_margin_deg': 180.0, 'power_mW': 4.75e-05, 'aux': {'bias_ok': True, 'vbp_dc': 1.584, 'voutp_dc': 0.914754, 'voutm_dc': 0.914754, 'mode': 'M-bin.0'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6 — FoM + constraints + validity + CONFIG  (REPLACEMENT)\n",
        "import random, numpy as np\n",
        "SEED = 1337\n",
        "random.seed(SEED); np.random.seed(SEED)\n",
        "\n",
        "# ------------------ CONFIG TOGGLES (adjust to taste) ------------------\n",
        "CFG = {\n",
        "    \"STRICT_CALIB_QUANTILES\": False,   # realistic (0.60/0.60/0.60/0.40) used in Step 7\n",
        "    \"RELAX_PCT\": 0.00,\n",
        "    \"EPS\": {\"gain_dB\": 1.0, \"ugbw_MHz\": 5.0, \"phase_margin_deg\": 3.0, \"power_mW\": 0.15},\n",
        "    \"USE_STRICT_BOUND_BUMP\": True,\n",
        "    \"BOUND_BUMP\": {\"gain_dB\": +1.0, \"ugbw_MHz\": +5.0, \"phase_margin_deg\": +2.0, \"power_mW\": -0.10},\n",
        "    \"SCORING_PM_CLAMP_DEG\": 90.0,\n",
        "}\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "EPS = dict(CFG[\"EPS\"])\n",
        "MIN_GAIN_DB = 0.10  # hard guard: skip any design with <= 0 dB gain\n",
        "\n",
        "def clamp_pm_for_scoring(pm_deg):\n",
        "    try:\n",
        "        cap = float(CFG[\"SCORING_PM_CLAMP_DEG\"])\n",
        "        v = float(pm_deg)\n",
        "        v = max(0.0, min(180.0, v))\n",
        "        return min(v, cap)\n",
        "    except Exception:\n",
        "        return 0.0\n",
        "\n",
        "def phi_geq(s, sb, eps):\n",
        "    if s is None:\n",
        "        return -1.0\n",
        "    sb_eff = sb + eps\n",
        "    return min(0.0, (s - sb_eff) / (abs(s) + abs(sb_eff) + 1e-12))\n",
        "\n",
        "def phi_leq(s, sb, eps):\n",
        "    if s is None:\n",
        "        return -1.0\n",
        "    sb_eff = sb - eps\n",
        "    return 0.0 if s <= sb_eff else (-(s - sb_eff) / (abs(s) + abs(sb_eff) + 1e-12))\n",
        "\n",
        "def ledro_terms(m, b):\n",
        "    # canonical per-term penalties with PM clamp for scoring view\n",
        "    return {\n",
        "        \"gain_dB\":          phi_geq(m[\"gain_dB\"],          b[\"gain_dB\"],          EPS[\"gain_dB\"]),\n",
        "        \"ugbw_MHz\":         phi_geq(m[\"ugbw_MHz\"],         b[\"ugbw_MHz\"],         EPS[\"ugbw_MHz\"]),\n",
        "        \"phase_margin_deg\": phi_geq(clamp_pm_for_scoring(m[\"phase_margin_deg\"]),\n",
        "                                     clamp_pm_for_scoring(b[\"phase_margin_deg\"]), EPS[\"phase_margin_deg\"]),\n",
        "        \"power_mW\":         phi_leq(m[\"power_mW\"],         b[\"power_mW\"],         EPS[\"power_mW\"]),\n",
        "    }\n",
        "\n",
        "def ledro_fom(m, b):\n",
        "    t = ledro_terms(m,b)\n",
        "    return t[\"gain_dB\"] + t[\"ugbw_MHz\"] + t[\"phase_margin_deg\"] + t[\"power_mW\"]\n",
        "\n",
        "def ledro_fom_w(m, b, w):\n",
        "    # normalized weighted FoM\n",
        "    t = ledro_terms(m,b)\n",
        "    ws = sum(w.values()) or 1.0\n",
        "    wnorm = {k: w[k]/ws for k in w}\n",
        "    return sum(wnorm[k]*t[k] for k in t)\n",
        "\n",
        "def electrically_valid(x):\n",
        "    for k,(lo,hi) in PDK[\"vars\"].items():\n",
        "        if not (lo <= x[k] <= hi):\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def metrics_valid(m):\n",
        "    vals = [m[\"gain_dB\"], m[\"ugbw_MHz\"], m[\"phase_margin_deg\"], m[\"power_mW\"]]\n",
        "    if not np.all(np.isfinite(vals)): return False\n",
        "    if m[\"gain_dB\"] <= MIN_GAIN_DB:   return False  # <<< NEW: hard screen on gain\n",
        "    if m[\"ugbw_MHz\"] <= 0.0:          return False\n",
        "    if m[\"phase_margin_deg\"] <= 0.0:  return False\n",
        "    if m[\"power_mW\"] <= 0.0:          return False\n",
        "    return True\n",
        "\n",
        "# Curriculum weights (adaptive)\n",
        "GLOBAL_W = {\"gain_dB\":1.0, \"ugbw_MHz\":1.0, \"phase_margin_deg\":1.0, \"power_mW\":1.0}\n"
      ],
      "metadata": {
        "id": "qbceyW5gSooa"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7 — Optimizer-based calibration per LEDRO (200 samples -> top-5)\n",
        "import numpy as np, json as _json\n",
        "from copy import deepcopy\n",
        "\n",
        "def clamp(lo,x,hi): return max(lo, min(x,hi))\n",
        "\n",
        "# ---------- Halton QMC ----------\n",
        "def _halton_component(n, base):\n",
        "    def vdc(i, b):\n",
        "        f, r = 1.0, 0.0\n",
        "        while i > 0:\n",
        "            f /= b; r += f * (i % b); i //= b\n",
        "        return r\n",
        "    return [vdc(i+1, base) for i in range(n)]\n",
        "\n",
        "def qmc_sample(ranges, n, start_index=0):\n",
        "    dims = list(ranges.keys())\n",
        "    bases = [2,3,5,7,11,13,17,19,23,29][:len(dims)]\n",
        "    seqs  = [np.array(_halton_component(n+start_index+1, b))[start_index:start_index+n] for b in bases]\n",
        "    out=[]\n",
        "    for i in range(n):\n",
        "        x={}\n",
        "        for (d, seq) in zip(dims, seqs):\n",
        "            lo,hi = ranges[d]; u = float(seq[i])\n",
        "            x[d] = lo + (hi-lo)*u\n",
        "        x[\"VDD\"] = PDK[\"VDD\"]\n",
        "        out.append(x)\n",
        "    return out\n",
        "\n",
        "# ---------- Loose validity for CALIBRATION ONLY ----------\n",
        "def metrics_valid_loose(m):\n",
        "    \"\"\"During calibration, accept any result with positive UGBW, PM, and Power; gain may be <= 0.\"\"\"\n",
        "    vals = [m[\"ugbw_MHz\"], m[\"phase_margin_deg\"], m[\"power_mW\"]]\n",
        "    if not np.all(np.isfinite(vals)):       return False\n",
        "    if m[\"ugbw_MHz\"] <= 0.0:               return False\n",
        "    if m[\"phase_margin_deg\"] <= 0.0:       return False\n",
        "    if m[\"power_mW\"] <= 0.0:               return False\n",
        "    return True\n",
        "\n",
        "# ---------- gm-boost candidates (bias to positive-gain regions) ----------\n",
        "def _gm_boost_candidates(ranges, n=32, seed=0):\n",
        "    rng = np.random.default_rng(20_000 + int(seed))\n",
        "    out=[]\n",
        "    glo = PDK[\"vars\"]\n",
        "    for _ in range(n):\n",
        "        x={}\n",
        "        # helper to bias toward upper quartile or lower for L\n",
        "        def upq(lo,hi,q=0.60,spread=0.40):\n",
        "            base = lo + q*(hi-lo)\n",
        "            span = spread*(hi-lo)\n",
        "            return clamp(lo, float(rng.uniform(base, min(hi, base+span))), hi)\n",
        "        def loq(lo,hi,q=0.25,spread=0.35):\n",
        "            base = lo + q*(hi-lo)\n",
        "            span = spread*(hi-lo)\n",
        "            return clamp(lo, float(rng.uniform(lo, max(lo, base))), hi)\n",
        "        # gm boosting: larger Wn/W2n, moderate L, higher Ib, reasonable Cc/Rz\n",
        "        w1_lo,w1_hi = glo[\"Wn_um\"];  x[\"Wn_um\"]  = max(8.0,  upq(w1_lo,w1_hi,0.60,0.40))\n",
        "        w2n_lo,w2n_hi=glo[\"W2n_um\"]; x[\"W2n_um\"] = max(6.0,  upq(w2n_lo,w2n_hi,0.55,0.45))\n",
        "        wp_lo,wp_hi  = glo[\"Wp_um\"];  x[\"Wp_um\"]  = upq(wp_lo,wp_hi,0.50,0.45)\n",
        "        w2p_lo,w2p_hi= glo[\"W2p_um\"]; x[\"W2p_um\"] = upq(w2p_lo,w2p_hi,0.50,0.45)\n",
        "        L_lo,L_hi    = glo[\"L_um\"];   x[\"L_um\"]   = loq(L_lo,L_hi,0.25,0.35)\n",
        "        Ib_lo,Ib_hi  = glo[\"Ib_mA\"];  x[\"Ib_mA\"]  = upq(Ib_lo,Ib_hi,0.55,0.45)\n",
        "        Cc_lo,Cc_hi  = glo[\"Ccomp_pF\"]; x[\"Ccomp_pF\"] = clamp(Cc_lo, float(rng.uniform(0.3,1.5)), Cc_hi)\n",
        "        Rz_lo,Rz_hi  = glo[\"Rz_ohm\"];   x[\"Rz_ohm\"]   = clamp(Rz_lo, float(rng.uniform(400.0,1500.0)), Rz_hi)\n",
        "        x[\"VDD\"] = PDK[\"VDD\"]\n",
        "        out.append(x)\n",
        "    return out\n",
        "\n",
        "# ---------- Ranking score for calibration ----------\n",
        "def score_calib(m):\n",
        "    if not metrics_valid_loose(m): return -1e9\n",
        "    # Favor gain, UGBW (log), some PM; penalize power.\n",
        "    return (1.00*m[\"gain_dB\"]\n",
        "            + 0.30*np.log10(max(m[\"ugbw_MHz\"], 1e-3))\n",
        "            + 0.10*clamp_pm_for_scoring(m[\"phase_margin_deg\"])\n",
        "            - 1.20*m[\"power_mW\"])\n",
        "\n",
        "def evaluate_batch_calib(batch):\n",
        "    allrecs=[]; best={\"score\":-1e9,\"design\":None,\"metrics\":None}\n",
        "    for x in batch:\n",
        "        if not electrically_valid(x):\n",
        "            continue\n",
        "        try:\n",
        "            m = simulate_metrics_ng(x)\n",
        "        except Exception:\n",
        "            continue\n",
        "        if not metrics_valid_loose(m):\n",
        "            continue\n",
        "        s = score_calib(m)\n",
        "        rec={\"score\":s,\"design\":x,\"metrics\":m}\n",
        "        allrecs.append(rec)\n",
        "        if s > best[\"score\"]: best = rec\n",
        "    return best, allrecs\n",
        "\n",
        "def _quantile_range_from_elites(elites, q_lo=0.20, q_hi=0.80, expand=0.05):\n",
        "    keys = list(elites[0][\"design\"].keys()); r={}\n",
        "    for k in keys:\n",
        "        vals = np.array([e[\"design\"][k] for e in elites], dtype=float)\n",
        "        lo,hi = float(np.quantile(vals, q_lo)), float(np.quantile(vals, q_hi))\n",
        "        width = hi - lo\n",
        "        lo -= expand*width; hi += expand*width\n",
        "        if k == \"VDD\": # Handle VDD separately as it's not in PDK[\"vars\"]\n",
        "            r[k] = (PDK[k], PDK[k])\n",
        "        else:\n",
        "            glo,ghi = PDK[\"vars\"][k]\n",
        "            r[k] = (clamp(glo, min(lo,hi), ghi), clamp(glo, max(lo,hi), ghi))\n",
        "    return r\n",
        "\n",
        "def cem_calib_search(ranges, total_budget=200, iters=4, pop=56, global_mix=0.20, seed0=0):\n",
        "    iters = max(1, min(iters, 6)); pop=max(16, pop)\n",
        "    curr=dict(ranges); budget_left=total_budget\n",
        "    all_records=[]; best={\"score\":-1e9,\"design\":None,\"metrics\":None}\n",
        "    for it in range(iters):\n",
        "        if budget_left<=0: break\n",
        "        n = min(pop, budget_left)\n",
        "        n_global = max(2, int(global_mix*n)); n_local=n-n_global\n",
        "        batch = qmc_sample(curr, n_local, start_index=seed0 + it*37)\n",
        "        batch += qmc_sample(ranges, n_global, start_index=seed0 + it*17)\n",
        "        b,tr = evaluate_batch_calib(batch)\n",
        "        all_records += tr; budget_left -= len(tr)\n",
        "        if b[\"score\"] > best[\"score\"]: best=b\n",
        "        if len(all_records)>=5:\n",
        "            k=max(5, int(0.22*len(all_records)))\n",
        "            elites = sorted(all_records, key=lambda r:-r[\"score\"])[:k]\n",
        "            curr = _quantile_range_from_elites(elites, q_lo=0.20, q_hi=0.80, expand=0.05)\n",
        "        # gm-boost rescue if very few valid records in this iter\n",
        "        if len(tr) < max(6, int(0.25*n)) and budget_left > 0:\n",
        "            n_boost = min(max(12, int(0.4*n)), budget_left)\n",
        "            boost = _gm_boost_candidates(PDK[\"vars\"], n=n_boost, seed=seed0 + it*101)\n",
        "            b2,tr2 = evaluate_batch_calib(boost)\n",
        "            all_records += tr2; budget_left -= len(tr2)\n",
        "            if b2[\"score\"] > best[\"score\"]: best=b2\n",
        "    return best, all_records\n",
        "\n",
        "# ---- Try calibration; if small/empty, auto-resample until we have enough ----\n",
        "def build_calibration_pool(min_valid=24, min_good=5, max_passes=8, base_budget=200):\n",
        "    pool, trace = [], []\n",
        "    # first pass\n",
        "    _, tr = cem_calib_search(PDK[\"vars\"], total_budget=base_budget, iters=4, pop=56, seed0=101)\n",
        "    trace += tr; pool += [{\"design\":r[\"design\"], \"metrics\":r[\"metrics\"]} for r in tr if metrics_valid_loose(r[\"metrics\"])]\n",
        "    passes = 1\n",
        "    while (len(pool) < min_valid or sum(1 for r in pool if r['metrics']['gain_dB'] > 0.0) < min_good) and passes < max_passes:\n",
        "        # QMC top-up\n",
        "        batch = qmc_sample(PDK[\"vars\"], 64, start_index=1000 + passes*67)\n",
        "        _, tr_q = evaluate_batch_calib(batch)\n",
        "        trace += tr_q; pool += [{\"design\":r[\"design\"], \"metrics\":r[\"metrics\"]} for r in tr_q]\n",
        "        # gm-boost top-up\n",
        "        boost = _gm_boost_candidates(PDK[\"vars\"], 32, seed=2000 + passes*113)\n",
        "        _, tr_b = evaluate_batch_calib(boost)\n",
        "        trace += tr_b; pool += [{\"design\":r[\"design\"], \"metrics\":r[\"metrics\"]} for r in tr_b]\n",
        "        passes += 1\n",
        "    return pool, trace, passes\n",
        "\n",
        "# ---- Run robust calibration ----\n",
        "CALIB_POOL, CALIB_TRACE, passes = build_calibration_pool(min_valid=24, min_good=5, max_passes=8, base_budget=200)\n",
        "\n",
        "if not CALIB_POOL:\n",
        "    raise RuntimeError(\"Calibration pool empty after resampling. Ensure simulator returns finite metrics.\")\n",
        "\n",
        "# Learn realistic bounds from the pool (quantiles), then optional bump\n",
        "def set_bounds_from_pool(pool, gq=0.60, uq=0.60, pmq=0.60, pq=0.40):\n",
        "    gains  = np.array([p[\"metrics\"][\"gain_dB\"] for p in pool if p[\"metrics\"][\"gain_dB\"] is not None])\n",
        "    ugs    = np.array([p[\"metrics\"][\"ugbw_MHz\"] for p in pool if p[\"metrics\"][\"ugbw_MHz\"] is not None])\n",
        "    pms    = np.array([clamp_pm_for_scoring(p[\"metrics\"][\"phase_margin_deg\"]) for p in pool if p[\"metrics\"][\"phase_margin_deg\"] is not None])\n",
        "    powers = np.array([p[\"metrics\"][\"power_mW\"] for p in pool if p[\"metrics\"][\"power_mW\"] is not None])\n",
        "\n",
        "    if min(map(len, (gains, ugs, pms, powers))) < 5:\n",
        "        raise RuntimeError(\"Calibration pool too small — re-check ngspice runner.\")\n",
        "\n",
        "    BOUND_CAL = {\n",
        "        \"gain_dB\":          float(np.quantile(gains, gq)),\n",
        "        \"ugbw_MHz\":         float(np.quantile(ugs,   uq)),\n",
        "        \"phase_margin_deg\": float(np.quantile(pms,   pmq)),\n",
        "        \"power_mW\":         float(np.quantile(powers,pq)),\n",
        "    }\n",
        "    # small bump\n",
        "    if CFG[\"USE_STRICT_BOUND_BUMP\"]:\n",
        "        BOUND_CAL[\"gain_dB\"]          += CFG[\"BOUND_BUMP\"][\"gain_dB\"]\n",
        "        BOUND_CAL[\"ugbw_MHz\"]         += CFG[\"BOUND_BUMP\"][\"ugbw_MHz\"]\n",
        "        BOUND_CAL[\"phase_margin_deg\"] += CFG[\"BOUND_BUMP\"][\"phase_margin_deg\"]\n",
        "        BOUND_CAL[\"power_mW\"]          = max(0.0, BOUND_CAL[\"power_mW\"] + CFG[\"BOUND_BUMP\"][\"power_mW\"])\n",
        "    return BOUND_CAL\n",
        "\n",
        "BOUND_CAL = set_bounds_from_pool(CALIB_POOL, gq=0.60, uq=0.60, pmq=0.60, pq=0.40)\n",
        "BOUND = dict(BOUND_CAL)  # no relax\n",
        "\n",
        "# Score pool by FoM and keep exactly 5 “good” (gain > 0 dB) exemplars for prompts\n",
        "def _fom_unw(m):\n",
        "    return ledro_fom({\n",
        "        \"gain_dB\": m[\"gain_dB\"],\n",
        "        \"ugbw_MHz\": m[\"ugbw_MHz\"],\n",
        "        \"phase_margin_deg\": clamp_pm_for_scoring(m[\"phase_margin_deg\"]),\n",
        "        \"power_mW\": m[\"power_mW\"],\n",
        "    }, b=BOUND)\n",
        "\n",
        "scored_pool=[]\n",
        "for p in CALIB_POOL:\n",
        "    scored_pool.append({\"fom\":_fom_unw(p[\"metrics\"]), \"design\":p[\"design\"], \"metrics\":p[\"metrics\"]})\n",
        "good = [s for s in scored_pool if s[\"metrics\"][\"gain_dB\"] > 0.0]\n",
        "good.sort(key=lambda r: r[\"fom\"], reverse=True)\n",
        "\n",
        "CALIB_TOP5 = (good[:5] if len(good) >= 5\n",
        "              else sorted(scored_pool, key=lambda r:r[\"fom\"], reverse=True)[:5])\n",
        "\n",
        "CALIB       = deepcopy(CALIB_TOP5)\n",
        "CALIB_COUNT = len(CALIB_POOL)\n",
        "BEST_CALIB  = max(scored_pool, key=lambda r: r[\"fom\"]) if scored_pool else None\n",
        "\n",
        "print(\"Calibration via optimizer completed.\")\n",
        "print(f\"Resample passes: {passes} | valid_pool={CALIB_COUNT} | good(gain>0)={sum(1 for r in CALIB_POOL if r['metrics']['gain_dB']>0)}\")\n",
        "print(\"Final BOUND:\", _json.dumps(BOUND, indent=2))\n",
        "print(\"EPS cushions:\", _json.dumps(EPS, indent=2))\n",
        "print(\"Top-5 'good' calibration exemplars:\")\n",
        "for i,c in enumerate(CALIB_TOP5,1):\n",
        "    print(f\"  {i}. FoM={c['fom']:+.4f} | metrics={c['metrics']}\")"
      ],
      "metadata": {
        "id": "eufSHBO1SodA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8 — Prompts & builders (with memories)  (REPLACEMENT)\n",
        "import json as _json\n",
        "\n",
        "TOPOLOGY = \"Fully-differential two-stage OTA (SKY130 1.8V).\"\n",
        "\n",
        "NETLIST_SKEL = \"\"\"\\\n",
        "* Fully Differential Two-Stage OTA (SKY130) — skeleton (placeholders)\n",
        ".param Wn={Wn_um}u Wp={Wp_um}u W2n={W2n_um}u W2p={W2p_um}u L={L_um}u\n",
        ".param Ibias={Ib_mA}mA Cc={Ccomp_pF}p Rz={Rz_ohm}\n",
        "* Miller Cc between outp/outn; Rz in series (zero-nulling).\n",
        "* Specs to optimize: gain (dB), UGBW (MHz), phase margin (deg), power (mW).\n",
        "\"\"\"\n",
        "\n",
        "# Heuristic hard guardrails that correlate with positive gain & decent gm\n",
        "HARD_GUARDRAILS = [\n",
        "    \"Ensure dc gain > 0 dB (reject ranges that likely produce < 0 dB).\",\n",
        "    \"Bias toward higher gm: do not set Wn_um or W2n_um too small; prefer mid→upper quartile.\",\n",
        "    \"Keep L_um moderate for speed: prefer L_um ≤ 0.8 µm unless explicitly justified.\",\n",
        "    \"If previous round shows poor gain, raise Ib_mA lower bound and Wn/W2n lower bounds.\",\n",
        "    \"Keep Ccomp_pF in a reasonable band (≈0.3–1.5 pF) and Rz_ohm ≈ 400–1500 Ω for stable compensation.\",\n",
        "]\n",
        "\n",
        "def pack_points(points):\n",
        "    lines=[]\n",
        "    for p in points:\n",
        "        m, f, d = p[\"metrics\"], p[\"fom\"], p[\"design\"]\n",
        "        lines.append(\n",
        "          f'metrics: gain={m[\"gain_dB\"]:.2f} dB, ugbw={m[\"ugbw_MHz\"]:.1f} MHz, '\n",
        "          f'PM={m[\"phase_margin_deg\"]:.1f}°, power={m[\"power_mW\"]:.3f} mW | FoM={f:.5f} | '\n",
        "          f'design={{Wn:{d[\"Wn_um\"]:.3f}, Wp:{d[\"Wp_um\"]:.3f}, W2n:{d[\"W2n_um\"]:.3f}, W2p:{d[\"W2p_um\"]:.3f}, '\n",
        "          f'L:{d[\"L_um\"]:.3f}, Ib:{d[\"Ib_mA\"]:.3f}, Cc:{d[\"Ccomp_pF\"]:.3f}, Rz:{d[\"Rz_ohm\"]:.1f}}}'\n",
        "        )\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "def pack_history_memos(memos, max_len=6):\n",
        "    if not memos: return \"[]\"\n",
        "    last = memos[-max_len:]\n",
        "    return _json.dumps(last, indent=2)\n",
        "\n",
        "def actor_first_round_prompt(calib_points, targets, eps, actor_memory=None, critic_memory=None):\n",
        "    actor_memory = actor_memory or []\n",
        "    critic_memory = critic_memory or []\n",
        "    sys = f\"You are the DESIGNER (Actor). Propose parameter RANGES only.\\nTopology: {TOPOLOGY}\\nObjective: minimize FoM violations (FoM ≤ 0).\"\n",
        "    bounds_text = {k:[float(lo),float(hi)] for k,(lo,hi) in PDK[\"vars\"].items()}\n",
        "    guard = \"\\n\".join([f\"- {g}\" for g in HARD_GUARDRAILS])\n",
        "    usr = f\"\"\"Round 1.\n",
        "\n",
        "Netlist skeleton (for knob context):\n",
        "{NETLIST_SKEL}\n",
        "\n",
        "Targets: {_json.dumps(targets)}\n",
        "ε cushions: {_json.dumps(eps)}\n",
        "PDK limits: {_json.dumps(bounds_text)}\n",
        "\n",
        "Calibration exemplars (top-5 FoM, gain>0 dB):\n",
        "{pack_points(calib_points)}\n",
        "\n",
        "Actor reflections to reuse:\n",
        "{pack_history_memos(actor_memory)}\n",
        "Critic guardrails to obey:\n",
        "{pack_history_memos(critic_memory)}\n",
        "\n",
        "**Hard guardrails (must follow):**\n",
        "{guard}\n",
        "\n",
        "**Requirements:**\n",
        "- Output *tight* ranges that likely improve FoM toward 0 and **keep gain > 0 dB**.\n",
        "- Encourage diversity vs exemplars (do not simply copy).\n",
        "- Prioritize higher gm: increase lower bounds on Wn/W2n and Ib_mA; keep L moderate.\n",
        "- Return JSON ONLY:\n",
        "{{\"ranges\": {{\"Wn_um\":[l,h],\"Wp_um\":[l,h],\"W2n_um\":[l,h],\"W2p_um\":[l,h],\"L_um\":[l,h],\"Ib_mA\":[l,h],\"Ccomp_pF\":[l,h],\"Rz_ohm\":[l,h]}}, \"notes\":\"rationale\"}}\"\"\"\n",
        "    return sys, usr\n",
        "\n",
        "def actor_feedback_prompt(critic_conf, critic_memo, top5_points, last_best, history_ranges, targets, eps,\n",
        "                          actor_memory=None, critic_memory=None, curriculum_focus=None):\n",
        "    actor_memory = actor_memory or []\n",
        "    critic_memory = critic_memory or []\n",
        "    sys = f\"You are the DESIGNER (Actor). Same circuit/topology.\\nTopology: {TOPOLOGY}\"\n",
        "    guard = \"\\n\".join([f\"- {g}\" for g in HARD_GUARDRAILS])\n",
        "    usr = f\"\"\"Feedback:\n",
        "Critic confidence: {critic_conf:.2f}\n",
        "Critic memo:\n",
        "{critic_memo}\n",
        "\n",
        "Recent top-5 (FoM):\n",
        "{pack_points(top5_points)}\n",
        "\n",
        "Current best so far:\n",
        "{_json.dumps(last_best, indent=2)}\n",
        "\n",
        "History of your approved ranges:\n",
        "{_json.dumps(history_ranges, indent=2)}\n",
        "\n",
        "Actor reflections to reuse:\n",
        "{pack_history_memos(actor_memory)}\n",
        "Critic guardrails to obey:\n",
        "{pack_history_memos(critic_memory)}\n",
        "Curriculum focus (most violated specs first): {curriculum_focus}\n",
        "\n",
        "**Hard guardrails (must follow):**\n",
        "{guard}\n",
        "\n",
        "**Task (diversify but focused):**\n",
        "- Propose *tight*, improved ranges centered near current best, but explore orthogonal DOFs.\n",
        "- If gain was weak/negative, explicitly raise **lower bounds** of Wn_um, W2n_um and Ib_mA, and reduce L_um upper bound.\n",
        "- Keep Cc and Rz in compensation-friendly bands.\n",
        "- Return JSON ONLY:\n",
        "{{\"ranges\": {{\"Wn_um\":[l,h],\"Wp_um\":[l,h],\"W2n_um\":[l,h],\"W2p_um\":[l,h],\"L_um\":[l,h],\"Ib_mA\":[l,h],\"Ccomp_pF\":[l,h],\"Rz_ohm\":[l,h]}}, \"notes\":\"brief rationale\"}}\"\"\"\n",
        "    return sys, usr\n",
        "\n",
        "def critic_audit_prompt(actor_ranges, validator_report, feedback_top5=None, last_best=None, critic_memory=None):\n",
        "    sys = \"You are the CRITIC. Audit/repair the Actor's ranges, return a numeric confidence and a short memo. Output VALID JSON only.\"\n",
        "    fb = \"\" if feedback_top5 is None else \"\\nTop-5 recent (FoM, design):\\n\" + \"\\n\".join(\n",
        "        [f'FoM={p[\"fom\"]:.5f} | {p[\"design\"]}' for p in feedback_top5]\n",
        "    )\n",
        "    lb = \"\" if last_best is None else \"\\nCurrent best so far:\\n\" + _json.dumps(last_best, indent=2)\n",
        "    mem = \"\" if not critic_memory else \"\\nCritic guardrail memory (apply these checks):\\n\" + pack_history_memos(critic_memory)\n",
        "    heur = (\n",
        "        \"\\nHeuristic checks (enforce if actor is too loose):\\n\"\n",
        "        \"- If lower bound of Wn_um or W2n_um is near zero, lift it to the mid-quantile of the global PDK range.\\n\"\n",
        "        \"- If L_um upper bound > 0.8 µm without justification, clip to ≤ 0.8 µm.\\n\"\n",
        "        \"- If Ib_mA lower bound < 0.2 mA and gain is weak, lift it toward 0.4–1.0 mA.\\n\"\n",
        "        \"- Keep Ccomp_pF within ≈0.3–1.5 pF and Rz_ohm ≈ 400–1500 Ω unless evidence suggests otherwise.\"\n",
        "    )\n",
        "    usr = (\n",
        "        \"Actor-proposed ranges:\\n\" + _json.dumps(actor_ranges, indent=2) +\n",
        "        f\"\\nValidator report: {validator_report}{fb}{lb}{mem}{heur}\\n\\n\"\n",
        "        \"Return JSON ONLY. DO NOT add commentary. Schema:\\n\"\n",
        "        \"{\\n\"\n",
        "        '  \"ranges\": {\"Wn_um\":[number,number], \"Wp_um\":[number,number], \"W2n_um\":[number,number], \"W2p_um\":[number,number], \"L_um\":[number,number], \"Ib_mA\":[number,number], \"Ccomp_pF\":[number,number], \"Rz_ohm\":[number,number]},\\n'\n",
        "        '  \"confidence\": number,\\n'\n",
        "        '  \"memo\": \"string\"\\n'\n",
        "        \"}\\n\"\n",
        "        \"Start your answer with '{' and end with '}'.\"\n",
        "    )\n",
        "    return sys, usr\n",
        "\n",
        "def actor_reflect_prompt(round_num, critic_memo, best_r, top5_r, weights, used_ranges):\n",
        "    sys = \"You are the DESIGNER (Actor). Reflect briefly and extract 2–4 actionable rules for the next round.\"\n",
        "    usr = f\"\"\"Round {round_num} summary (Actor view):\n",
        "- Critic memo: {critic_memo}\n",
        "- Best metrics: {best_r['metrics']}\n",
        "- Used ranges: {used_ranges}\n",
        "- Curriculum weights: {weights}\n",
        "- Top-5 FoM+designs:\\n{pack_points(top5_r)}\n",
        "\n",
        "Return compact JSON ONLY:\n",
        "{{\"reflection\":\"1-2 sentence lesson\",\"rules\":[\"short imperative rule 1\",\"raise Wn/W2n/Ib if gain weak\",\"clip L upper bound\",\"keep Cc 0.3–1.5pF, Rz 400–1500Ω\"]}}\"\"\"\n",
        "    return sys, usr\n",
        "\n",
        "def critic_reflect_prompt(round_num, best_r, all_r, weights, used_ranges):\n",
        "    sys = \"You are the CRITIC. Reflect and update guardrails for auditing Actor ranges.\"\n",
        "    worst = \"unknown\"\n",
        "    try:\n",
        "        v = {\"gain_dB\":0,\"ugbw_MHz\":0,\"phase_margin_deg\":0,\"power_mW\":0}\n",
        "        for rec in all_r:\n",
        "            t = ledro_terms(rec[\"metrics\"], BOUND)\n",
        "            for k in v: v[k] += -float(t[k])\n",
        "        worst = max(v, key=lambda k: v[k])\n",
        "    except Exception:\n",
        "        pass\n",
        "    usr = f\"\"\"Round {round_num} summary (Critic view):\n",
        "- Best metrics: {best_r['metrics']}\n",
        "- Used ranges: {used_ranges}\n",
        "- Curriculum weights: {weights}\n",
        "- Most violated (approx): {worst}\n",
        "\n",
        "Return compact JSON ONLY:\n",
        "{{\"memo\":\"1-2 sentence takeaway\",\"guardrails\":[\"lift Wn/W2n/Ib lower bounds if gain poor\",\"clip L upper bound if UGBW poor\",\"keep comp: Cc 0.3–1.5pF, Rz 400–1500Ω\"]}}\"\"\"\n",
        "    return sys, usr\n"
      ],
      "metadata": {
        "id": "z1AdtVdgSobB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9 — Role callers  (REPLACEMENT)\n",
        "def ask_actor(messages, **gen):\n",
        "    model, tok = get_shared_llm()\n",
        "    return chat(model, tok, messages, **({\n",
        "        \"temperature\": 0.45,    # was 0.70\n",
        "        \"top_p\": 0.85,          # was 0.95\n",
        "        \"greedy\": False,\n",
        "        \"max_new_tokens\": 96,\n",
        "        \"repetition_penalty\": 1.07,  # was 1.02\n",
        "        \"max_time\": 8.0\n",
        "    } | gen))\n",
        "\n",
        "def ask_critic(messages, **gen):\n",
        "    model, tok = get_shared_llm()\n",
        "    return chat(model, tok, messages, **({\n",
        "        \"temperature\": 0.0,\n",
        "        \"greedy\": True,\n",
        "        \"max_new_tokens\": 96,\n",
        "        \"max_time\": 6.0\n",
        "    } | gen))\n"
      ],
      "metadata": {
        "id": "WZHbpcd3SoZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10 — Validator\n",
        "def clamp(lo,x,hi): return max(lo, min(x,hi))\n",
        "\n",
        "def validate_ranges(ranges):\n",
        "    repaired, notes = {}, []\n",
        "    for k,(glo,ghi) in PDK[\"vars\"].items():\n",
        "        lo,hi = ranges.get(k,(glo,ghi))\n",
        "        lo,hi = float(lo), float(hi)\n",
        "        lo,hi = clamp(glo,lo,ghi), clamp(glo,hi,ghi)\n",
        "        if hi < lo: lo,hi = hi,lo\n",
        "        repaired[k] = (lo,hi)\n",
        "    return repaired, (\"; \".join(notes) if notes else \"OK\")\n"
      ],
      "metadata": {
        "id": "dFayQV3wSoXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 11 — Optimizer core (QMC + CEM) + guards  (REPLACEMENT)\n",
        "import numpy as np, re, json, gc, torch\n",
        "\n",
        "def avg_width(r):\n",
        "    return sum((hi-lo) for (lo,hi) in r.values())/len(r)\n",
        "\n",
        "def shrink_around(design, base_ranges, frac=0.35):\n",
        "    new={}\n",
        "    for k,(lo,hi) in base_ranges.items():\n",
        "        width = (hi-lo)*frac*0.5\n",
        "        c = float(design[k])\n",
        "        a,b = clamp(lo,c-width,hi), clamp(lo,c+width,hi)\n",
        "        if b <= a: b = min(hi, a + 1e-9)\n",
        "        new[k]=(a,b)\n",
        "    return new\n",
        "\n",
        "def mix_ranges(local, global_ranges, mix=0.15):\n",
        "    out={}\n",
        "    for k,(glo,ghi) in global_ranges.items():\n",
        "        lo,hi = local[k]\n",
        "        out[k] = ((1-mix)*lo + mix*glo, (1-mix)*hi + mix*ghi)\n",
        "    return out\n",
        "\n",
        "# Halton + sampler\n",
        "def _halton_component(n, base):\n",
        "    def vdc(i, b):\n",
        "        f, r = 1.0, 0.0\n",
        "        while i > 0:\n",
        "            f /= b; r += f * (i % b); i //= b\n",
        "        return r\n",
        "    return [vdc(i+1, base) for i in range(n)]\n",
        "\n",
        "def qmc_sample(ranges, n, start_index=0):\n",
        "    dims = list(ranges.keys())\n",
        "    bases = [2,3,5,7,11,13,17,19,23,29][:len(dims)]\n",
        "    seqs  = [np.array(_halton_component(n+start_index+1, b))[start_index:start_index+n] for b in bases]\n",
        "    out=[]\n",
        "    for i in range(n):\n",
        "        x={}\n",
        "        for (d, seq) in zip(dims, seqs):\n",
        "            lo,hi = ranges[d]; u = float(seq[i])\n",
        "            x[d] = lo + (hi-lo) * u\n",
        "        out.append(x)\n",
        "    return out\n",
        "\n",
        "# --- NEW: gm-biased rescue candidates (favor positive gain / higher gm) ---\n",
        "def _gm_boost_candidates(ranges, n=24, seed=0):\n",
        "    rng = np.random.default_rng(10_000 + int(seed))\n",
        "    out=[]\n",
        "    for _ in range(n):\n",
        "        x={}\n",
        "        # helper to bias toward upper quartile or lower for L\n",
        "        def upq(lo,hi,q=0.60,spread=0.40):\n",
        "            base = lo + q*(hi-lo)\n",
        "            span = spread*(hi-lo)\n",
        "            return clamp(lo, float(rng.uniform(base, min(hi, base+span))), hi)\n",
        "        def loq(lo,hi,q=0.30,spread=0.30):\n",
        "            base = lo + q*(hi-lo)\n",
        "            span = spread*(hi-lo)\n",
        "            return clamp(lo, float(rng.uniform(lo, max(lo, base))), hi)\n",
        "        glo = PDK[\"vars\"]\n",
        "        # gm boosting: larger input/2nd‑stage NFETs, moderate L, higher Ib\n",
        "        w1_lo,w1_hi = glo[\"Wn_um\"]; x[\"Wn_um\"]  = max(10.0, upq(w1_lo,w1_hi,0.60,0.40))\n",
        "        w2n_lo,w2n_hi = glo[\"W2n_um\"]; x[\"W2n_um\"] = max(8.0,  upq(w2n_lo,w2n_hi,0.55,0.45))\n",
        "        wp_lo,wp_hi = glo[\"Wp_um\"]; x[\"Wp_um\"]  = upq(wp_lo,wp_hi,0.50,0.45)\n",
        "        w2p_lo,w2p_hi = glo[\"W2p_um\"]; x[\"W2p_um\"] = upq(w2p_lo,w2p_hi,0.50,0.45)\n",
        "        L_lo,L_hi   = glo[\"L_um\"]; x[\"L_um\"]   = loq(L_lo,L_hi,0.25,0.35)   # shorter for UGBW\n",
        "        Ib_lo,Ib_hi = glo[\"Ib_mA\"]; x[\"Ib_mA\"] = upq(Ib_lo,Ib_hi,0.55,0.45) # more bias\n",
        "        Cc_lo,Cc_hi = glo[\"Ccomp_pF\"]; x[\"Ccomp_pF\"] = clamp(Cc_lo, float(rng.uniform(0.3,1.5)), Cc_hi)\n",
        "        Rz_lo,Rz_hi = glo[\"Rz_ohm\"];    x[\"Rz_ohm\"]   = clamp(Rz_lo, float(rng.uniform(400.0,1500.0)), Rz_hi)\n",
        "        out.append(x)\n",
        "    return out\n",
        "\n",
        "def evaluate_batch(batch, weights=None):\n",
        "    trace=[]; best={\"fom\":-1e9,\"design\":None,\"metrics\":None}\n",
        "    for x in batch:\n",
        "        if not electrically_valid(x):\n",
        "            continue\n",
        "        try:\n",
        "            m = simulate_metrics_ng(x)\n",
        "        except Exception:\n",
        "            continue\n",
        "        if not metrics_valid(m):  # enforces gain_dB > MIN_GAIN_DB, UGBW>0, PM>0, power>0\n",
        "            continue\n",
        "        m2 = {\n",
        "            \"gain_dB\": m[\"gain_dB\"],\n",
        "            \"ugbw_MHz\": m[\"ugbw_MHz\"],\n",
        "            \"phase_margin_deg\": clamp_pm_for_scoring(m[\"phase_margin_deg\"]),\n",
        "            \"power_mW\": m[\"power_mW\"],\n",
        "        }\n",
        "        f = ledro_fom_w(m2, b=BOUND, w=weights if weights else {\"gain_dB\":1,\"ugbw_MHz\":1,\"phase_margin_deg\":1,\"power_mW\":1})\n",
        "        rec={\"fom\":f,\"design\":x,\"metrics\":m}\n",
        "        trace.append(rec)\n",
        "        if f > best[\"fom\"]: best = rec\n",
        "    return best, trace\n",
        "\n",
        "def _quantile_range_from_elites(elites, q_lo=0.20, q_hi=0.80, expand=0.05):\n",
        "    keys = list(elites[0][\"design\"].keys())\n",
        "    r={}\n",
        "    for k in keys:\n",
        "        vals = np.array([e[\"design\"][k] for e in elites], dtype=float)\n",
        "        lo,hi = float(np.quantile(vals, q_lo)), float(np.quantile(vals, q_hi))\n",
        "        width = hi - lo\n",
        "        lo -= expand*width; hi += expand*width\n",
        "        glo,ghi = PDK[\"vars\"][k]\n",
        "        r[k] = (clamp(glo, min(lo,hi), ghi), clamp(glo, max(lo,hi), ghi))\n",
        "    return r\n",
        "\n",
        "def robust_stat(trace, q=0.65):\n",
        "    if not trace: return -1e9\n",
        "    foms = np.array([r[\"fom\"] for r in trace], dtype=float)\n",
        "    return float(np.quantile(foms, q))\n",
        "\n",
        "def accept_new_round(prev_hist, new_trace, margin=0.015, q=0.65):\n",
        "    if not prev_hist: return True\n",
        "    prev = robust_stat(prev_hist[-1][\"all\"], q=q)\n",
        "    curr = robust_stat(new_trace, q=q)\n",
        "    return (curr >= prev - margin)\n",
        "\n",
        "def cem_search(ranges, weights=None, best_so_far=None, total_budget=100, round_num=1,\n",
        "               iters=3, pop=36, elite_frac=0.22, global_mix=0.15, seed_offset=0):\n",
        "    iters = max(1, min(iters, 6))\n",
        "    pop   = max(16, pop)\n",
        "    budget_left = total_budget\n",
        "    all_records=[]\n",
        "    best = {\"fom\":-1e9,\"design\":None,\"metrics\":None}\n",
        "\n",
        "    curr = dict(ranges)\n",
        "    if best_so_far and best_so_far.get(\"design\"):\n",
        "        tr = shrink_around(best_so_far[\"design\"], curr, frac={1:0.30, 2:0.25, 3:0.20}.get(round_num, 0.20))\n",
        "        for k,(lo,hi) in tr.items():\n",
        "            glo,ghi = ranges[k]\n",
        "            curr[k] = (max(glo,lo), min(ghi,hi))\n",
        "\n",
        "    for it in range(iters):\n",
        "        if budget_left <= 0: break\n",
        "        n = min(pop, budget_left)\n",
        "\n",
        "        n_global = max(2, int(global_mix*n))\n",
        "        n_local  = n - n_global\n",
        "        batch = qmc_sample(curr, n_local, start_index=seed_offset + it*37)\n",
        "        batch += qmc_sample(ranges, n_global, start_index=seed_offset + it*17)\n",
        "\n",
        "        b, tr = evaluate_batch(batch, weights=weights)\n",
        "        all_records += tr\n",
        "        budget_left -= len(tr)\n",
        "        if b[\"fom\"] > best[\"fom\"]: best = b\n",
        "\n",
        "        # --- NEW: gm-boost if too few valid positive-gain points this iter\n",
        "        if len(tr) < max(6, int(0.25*n)) and budget_left > 0:\n",
        "            n_boost = min(max(10, int(0.5*n)), budget_left)\n",
        "            boost_batch = _gm_boost_candidates(PDK[\"vars\"], n=n_boost, seed=seed_offset + it*101)\n",
        "            b2, tr2 = evaluate_batch(boost_batch, weights=weights)\n",
        "            all_records += tr2\n",
        "            budget_left -= len(tr2)\n",
        "            if b2[\"fom\"] > best[\"fom\"]: best = b2\n",
        "\n",
        "        # update contraction box if we have enough records\n",
        "        if len(all_records) >= 5:\n",
        "            k = max(5, int(elite_frac*len(all_records)))\n",
        "            elites = sorted(all_records, key=lambda r:-r[\"fom\"])[:k]\n",
        "            curr = _quantile_range_from_elites(elites, q_lo=0.20, q_hi=0.80, expand=0.05)\n",
        "\n",
        "    # Global fallback if absolutely nothing valid\n",
        "    if not all_records and budget_left > 0:\n",
        "        fb = _gm_boost_candidates(PDK[\"vars\"], max(32, pop), seed=seed_offset + 911)\n",
        "        b2, tr2 = evaluate_batch(fb, weights=weights)\n",
        "        all_records += tr2\n",
        "        if tr2 and b2[\"fom\"] > best[\"fom\"]:\n",
        "            best = b2\n",
        "\n",
        "    top5 = sorted(all_records, key=lambda r:-r[\"fom\"])[:5] if all_records else []\n",
        "    return best, top5, all_records\n",
        "\n",
        "# ---- Normalized, bounded weight update ----\n",
        "def update_weights_from_trace(samples, w_prev, step=0.25, floor=0.15, cap=0.45):\n",
        "    keys = [\"gain_dB\",\"ugbw_MHz\",\"phase_margin_deg\",\"power_mW\"]\n",
        "    deficits = {k: [] for k in keys}\n",
        "    for s in samples:\n",
        "        m = {\n",
        "            \"gain_dB\": s[\"metrics\"][\"gain_dB\"],\n",
        "            \"ugbw_MHz\": s[\"metrics\"][\"ugbw_MHz\"],\n",
        "            \"phase_margin_deg\": clamp_pm_for_scoring(s[\"metrics\"][\"phase_margin_deg\"]),\n",
        "            \"power_mW\": s[\"metrics\"][\"power_mW\"],\n",
        "        }\n",
        "        t = ledro_terms(m, BOUND)\n",
        "        for k in keys:\n",
        "            deficits[k].append(abs(t[k]))\n",
        "\n",
        "    avg_def = {k: (float(np.mean(deficits[k])) if deficits[k] else 0.0) for k in keys}\n",
        "    total = sum(avg_def.values()) + 1e-12\n",
        "    target = {k: (avg_def[k] / total) for k in keys}\n",
        "\n",
        "    w = dict(w_prev)\n",
        "    for k in keys:\n",
        "        w[k] = (1.0 - step) * w.get(k, 0.25) + step * target[k]\n",
        "\n",
        "    # clamp and renormalize\n",
        "    for k in keys:\n",
        "        w[k] = min(max(w[k], floor), cap)\n",
        "    s = sum(w.values()) or 1.0\n",
        "    w = {k: w[k] / s for k in keys}\n",
        "    return w\n"
      ],
      "metadata": {
        "id": "B-WehPv_SoVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 11.5 — Ensemble Critic with memory input\n",
        "def critic_ensemble_audit(cand_ranges, cand_note, history, best_so_far, critic_memory, n_critics=3):\n",
        "    preds=[]\n",
        "    for i in range(n_critics):\n",
        "        sysC, usrC = critic_audit_prompt(\n",
        "            {\"ranges\": cand_ranges, \"notes\": cand_note + f\" | pass#{i+1}\"}, \"OK\",\n",
        "            feedback_top5=(history[-1][\"top5\"] if history else None),\n",
        "            last_best=(best_so_far if history else None),\n",
        "            critic_memory=critic_memory\n",
        "        )\n",
        "        outC = ask_critic(\n",
        "            [{\"role\":\"system\",\"content\":sysC},{\"role\":\"user\",\"content\":usrC}],\n",
        "            temperature=0.15, top_p=0.35, greedy=False, max_new_tokens=96, max_time=6.0\n",
        "        )\n",
        "        try:\n",
        "            cj = find_json_block(outC)\n",
        "        except Exception:\n",
        "            import re, json as _json\n",
        "            m = re.search(r\"\\{[\\s\\S]*\\}\", outC)\n",
        "            cj = _json.loads(m.group(0)) if m else None\n",
        "        if cj is None:\n",
        "            cj = {\"ranges\": cand_ranges, \"confidence\": 0.55, \"memo\": \"fallback-critic-ens\"}\n",
        "        r, _ = validate_ranges(cj.get(\"ranges\", cand_ranges))\n",
        "        conf = float(cj.get(\"confidence\", 0.55))\n",
        "        preds.append((r, conf, cj.get(\"memo\",\"\")))\n",
        "\n",
        "    keys = list(cand_ranges.keys())\n",
        "    agg={}\n",
        "    for k in keys:\n",
        "        los = sorted([ (r[k][0], c) for (r,c,_) in preds ], key=lambda t:t[0])\n",
        "        his = sorted([ (r[k][1], c) for (r,c,_) in preds ], key=lambda t:t[0])\n",
        "        trim = max(0, int(0.2*len(los)))\n",
        "        los = los[trim: len(los)-trim or None]\n",
        "        his = his[trim: len(his)-trim or None]\n",
        "        wlo = sum(v*cf for v,cf in los) / max(1e-9, sum(cf for _,cf in los))\n",
        "        whi = sum(v*cf for v,cf in his) / max(1e-9, sum(cf for _,cf in his))\n",
        "        glo,ghi = PDK[\"vars\"][k]\n",
        "        agg[k] = (clamp(glo, min(wlo,whi), ghi), clamp(glo, max(wlo,whi), ghi))\n",
        "\n",
        "    mean_conf = float(np.mean([c for _,c,_ in preds]))\n",
        "    memo = \" | \".join([m for *_,m in preds[:2]])\n",
        "    return agg, mean_conf, memo\n"
      ],
      "metadata": {
        "id": "OPBOZmExSoTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 12 — Actor–Critic (LEDRO-style) with self-reflection  (REPLACEMENT)\n",
        "import re, json, gc, torch\n",
        "\n",
        "def parse_json_loose(txt):\n",
        "    m = re.search(r\"\\{[\\s\\S]*\\}\", txt)\n",
        "    if not m:\n",
        "        raise ValueError(\"no json block\")\n",
        "    return json.loads(m.group(0))\n",
        "\n",
        "history = []\n",
        "best_so_far = BEST_CALIB if 'BEST_CALIB' in globals() and BEST_CALIB else {\"fom\":-1e9,\"design\":None,\"metrics\":None}\n",
        "\n",
        "# Memories (self-reflection)\n",
        "ACTOR_MEM, CRITIC_MEM = [], []\n",
        "\n",
        "# ---- Sample-efficient settings ----\n",
        "N_ACTOR = 4\n",
        "N_CRITICS_ENSEMBLE = 3\n",
        "CEM_ITERS = 2\n",
        "TOTAL_SIMS_PER_ROUND = 60\n",
        "\n",
        "GLOBAL_W = {\"gain_dB\":1.0, \"ugbw_MHz\":1.0, \"phase_margin_deg\":1.0, \"power_mW\":1.0}\n",
        "\n",
        "for r in range(1, 3+1):\n",
        "    # Actor proposals (memory-aware, with top-5 calibration in R1)\n",
        "    if r == 1:\n",
        "        sysA, usrA = actor_first_round_prompt(CALIB, targets=BOUND, eps=EPS,\n",
        "                                              actor_memory=ACTOR_MEM, critic_memory=CRITIC_MEM)\n",
        "        temps = [0.55, 0.45, 0.35, 0.25]  # more conservative than before\n",
        "    else:\n",
        "        sysA, usrA = actor_feedback_prompt(\n",
        "            critic_conf=history[-1].get(\"critic_conf\", 0.5),\n",
        "            critic_memo=history[-1].get(\"critic_memo\",\"\"),\n",
        "            top5_points=history[-1][\"top5\"], last_best=best_so_far,\n",
        "            history_ranges=[h[\"critic_ranges\"] for h in history],\n",
        "            targets=BOUND, eps=EPS,\n",
        "            actor_memory=ACTOR_MEM, critic_memory=CRITIC_MEM,\n",
        "            curriculum_focus=dict(sorted(GLOBAL_W.items(), key=lambda kv:-kv[1]))\n",
        "        )\n",
        "        temps = [0.50, 0.40, 0.30, 0.25]\n",
        "\n",
        "    actor_candidates = []\n",
        "    for temp in temps:\n",
        "        outA = ask_actor(\n",
        "            [{\"role\":\"system\",\"content\":sysA},{\"role\":\"user\",\"content\":usrA}],\n",
        "            temperature=temp, top_p=0.85, repetition_penalty=1.07,\n",
        "            max_new_tokens=96, max_time=7.0\n",
        "        )\n",
        "        try:\n",
        "            actor_json = find_json_block(outA)\n",
        "        except Exception:\n",
        "            actor_json = {\"ranges\": ({k:list(v) for k,v in PDK[\"vars\"].items()} if r==1 else history[-1][\"critic_ranges\"]),\n",
        "                          \"notes\": f\"fallback-actor-r{r}\"}\n",
        "        r_raw = actor_json.get(\"ranges\", {})\n",
        "        r_val,_ = validate_ranges(r_raw)\n",
        "        actor_candidates.append((r_val, actor_json.get(\"notes\",\"\")))\n",
        "\n",
        "    # Ensemble critic audit\n",
        "    best_conf   = -1.0\n",
        "    chosen      = None\n",
        "    chosen_conf = 0.5\n",
        "    chosen_memo = \"\"\n",
        "\n",
        "    for cand_ranges, cand_note in actor_candidates:\n",
        "        agg_ranges, mean_conf, memo = critic_ensemble_audit(\n",
        "            cand_ranges, cand_note, history, best_so_far, CRITIC_MEM, n_critics=N_CRITICS_ENSEMBLE\n",
        "        )\n",
        "        if (mean_conf > best_conf) or (abs(mean_conf - best_conf) < 1e-9 and avg_width(agg_ranges) < (avg_width(chosen[0]) if chosen else 1e9)):\n",
        "            chosen      = (agg_ranges, memo)\n",
        "            best_conf   = mean_conf\n",
        "            chosen_conf = float(mean_conf)\n",
        "            chosen_memo = memo\n",
        "\n",
        "    if chosen is None:\n",
        "        chosen = (actor_candidates[0][0], \"fallback-none-chosen\")\n",
        "        chosen_conf = 0.55\n",
        "\n",
        "    # Trust-region contraction around current best, then blend with global\n",
        "    center = best_so_far[\"design\"] if (best_so_far and best_so_far.get(\"design\")) else None\n",
        "    if center is not None:\n",
        "        frac = {1:0.22, 2:0.20, 3:0.18}.get(r, 0.18)\n",
        "        r_use = shrink_around(center, chosen[0], frac=frac)\n",
        "        r_use,_ = validate_ranges(r_use)\n",
        "        r_use = mix_ranges(r_use, PDK[\"vars\"], mix=0.15)\n",
        "        r_use,_ = validate_ranges(r_use)\n",
        "    else:\n",
        "        r_use = chosen[0]\n",
        "\n",
        "    # Inner-loop search (CEM + QMC) with curriculum weights\n",
        "    seed_off = 2000*r + 31\n",
        "    best_r, top5_r, all_r = cem_search(\n",
        "        r_use, weights=GLOBAL_W, best_so_far=best_so_far, total_budget=TOTAL_SIMS_PER_ROUND,\n",
        "        round_num=r, iters=CEM_ITERS, pop=max(24, TOTAL_SIMS_PER_ROUND//CEM_ITERS),\n",
        "        global_mix=0.22, seed_offset=seed_off  # a bit more global mix to escape low-gain traps\n",
        "    )\n",
        "\n",
        "    # Guardrail: rescue if not robustly better (small, sample‑efficient)\n",
        "    if not accept_new_round(history, all_r, margin=0.015, q=0.65):\n",
        "        rescue_ranges = shrink_around(best_so_far[\"design\"], r_use, frac=0.14) if best_so_far.get(\"design\") else r_use\n",
        "        rescue_ranges,_ = validate_ranges(rescue_ranges)\n",
        "        seed_off = 3000*r + 17\n",
        "        best_r2, top5_r2, all_r2 = cem_search(\n",
        "            rescue_ranges, weights=GLOBAL_W, best_so_far=best_so_far, total_budget=int(0.4*TOTAL_SIMS_PER_ROUND),\n",
        "            round_num=r, iters=1, pop=max(20, TOTAL_SIMS_PER_ROUND//3),\n",
        "            global_mix=0.25, seed_offset=seed_off\n",
        "        )\n",
        "        if robust_stat(all_r2) > robust_stat(all_r):\n",
        "            best_r, top5_r, all_r = best_r2, top5_r2, all_r2\n",
        "\n",
        "    # Per‑term FoM logging\n",
        "    mlog = {\n",
        "        \"gain_dB\": best_r[\"metrics\"][\"gain_dB\"],\n",
        "        \"ugbw_MHz\": best_r[\"metrics\"][\"ugbw_MHz\"],\n",
        "        \"phase_margin_deg\": clamp_pm_for_scoring(best_r[\"metrics\"][\"phase_margin_deg\"]),\n",
        "        \"power_mW\": best_r[\"metrics\"][\"power_mW\"],\n",
        "    }\n",
        "    tlog = ledro_terms(mlog, BOUND)\n",
        "    print(\n",
        "        f\"[AC R{r}] FoM={best_r['fom']:+.8f} | \"\n",
        "        f\"terms: gain={tlog['gain_dB']:+.3f}, ugbw={tlog['ugbw_MHz']:+.3f}, pm={tlog['phase_margin_deg']:+.3f}, pwr={tlog['power_mW']:+.3f} | \"\n",
        "        f\"metrics={best_r['metrics']} | conf={chosen_conf:.2f} | W={GLOBAL_W}\"\n",
        "    )\n",
        "\n",
        "    if (best_so_far is None) or (best_r[\"fom\"] > best_so_far[\"fom\"]):\n",
        "        best_so_far = best_r\n",
        "\n",
        "    GLOBAL_W = update_weights_from_trace(all_r, GLOBAL_W, step=0.25)\n",
        "\n",
        "    # Reflections (critic → actor memo next round)\n",
        "    try:\n",
        "        sysAR, usrAR = actor_reflect_prompt(r, chosen_memo, best_r, top5_r, GLOBAL_W, r_use)\n",
        "        outAR = ask_actor([{\"role\":\"system\",\"content\":sysAR},{\"role\":\"user\",\"content\":usrAR}], temperature=0.25, greedy=False, max_new_tokens=96)\n",
        "        arj = find_json_block(outAR)\n",
        "        ACTOR_MEM.append(arj.get(\"reflection\",\"\") + \" | \" + \"; \".join(arj.get(\"rules\",[])[:3]))\n",
        "        ACTOR_MEM[:] = ACTOR_MEM[-6:]\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    try:\n",
        "        sysCR, usrCR = critic_reflect_prompt(r, best_r, all_r, GLOBAL_W, r_use)\n",
        "        outCR = ask_critic([{\"role\":\"system\",\"content\":sysCR},{\"role\":\"user\",\"content\":usrCR}], max_new_tokens=96)\n",
        "        crj = find_json_block(outCR)\n",
        "        CRITIC_MEM.append(crj.get(\"memo\",\"\") + \" | \" + \"; \".join(crj.get(\"guardrails\",[])[:3]))\n",
        "        CRITIC_MEM[:] = CRITIC_MEM[-6:]\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    history.append({\n",
        "        \"round\": r,\n",
        "        \"actor_ranges\": actor_candidates[0][0],\n",
        "        \"critic_ranges\": r_use,\n",
        "        \"critic_conf\": float(chosen_conf),\n",
        "        \"critic_memo\": chosen_memo,\n",
        "        \"best\": best_r,\n",
        "        \"top5\": top5_r,\n",
        "        \"all\":  all_r,\n",
        "        \"weights\": dict(GLOBAL_W),\n",
        "        \"actor_mem\": list(ACTOR_MEM),\n",
        "        \"critic_mem\": list(CRITIC_MEM),\n",
        "    })\n",
        "\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "6fUJl9o0SoIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 13 — Results table (Actor–Critic)\n",
        "import pandas as pd\n",
        "\n",
        "rows_ac=[]\n",
        "for h in history:\n",
        "    b=h[\"best\"]; m=b[\"metrics\"]; d=b[\"design\"]\n",
        "    rows_ac.append({\n",
        "        \"Round\":h[\"round\"], \"FoM\":b[\"fom\"], \"gap_to_zero\":-b[\"fom\"],\n",
        "        \"gain_dB\":m[\"gain_dB\"], \"ugbw_MHz\":m[\"ugbw_MHz\"], \"PM_deg\":m[\"phase_margin_deg\"], \"power_mW\":m[\"power_mW\"],\n",
        "        \"Wn_um\":d[\"Wn_um\"], \"Wp_um\":d[\"Wp_um\"], \"W2n_um\":d[\"W2n_um\"], \"W2p_um\":d[\"W2p_um\"],\n",
        "        \"L_um\":d[\"L_um\"], \"Ib_mA\":d[\"Ib_mA\"], \"Ccomp_pF\":d[\"Ccomp_pF\"], \"Rz_ohm\":d[\"Rz_ohm\"],\n",
        "        \"Self_conf\":round(h.get(\"critic_conf\",0.5), 2)\n",
        "    })\n",
        "df_ac = pd.DataFrame(rows_ac).round(4)\n",
        "df_ac\n"
      ],
      "metadata": {
        "id": "605o5wT6SoG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Free AC models so Single‑LLM loads a FRESH instance\n",
        "free_all_roles()\n"
      ],
      "metadata": {
        "id": "S9aJW5Y4SoE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 14 — Single‑LLM (with lightweight reflections)\n",
        "def ask_self_actor(messages, **gen):\n",
        "    model, tok = get_fresh_llm(\"single_actor_fresh\")\n",
        "    return chat(model, tok, messages, **({\n",
        "        \"temperature\": 0.70, \"top_p\": 0.95, \"greedy\": False,\n",
        "        \"max_new_tokens\": 96, \"repetition_penalty\": 1.00, \"max_time\": 6.0\n",
        "    } | gen))\n",
        "\n",
        "def ask_self_critic(messages, **gen):\n",
        "    model, tok = get_fresh_llm(\"single_critic_fresh\")\n",
        "    return chat(model, tok, messages, **({\n",
        "        \"temperature\": 0.0, \"greedy\": True,\n",
        "        \"max_new_tokens\": 96, \"max_time\": 5.0\n",
        "    } | gen))\n",
        "\n",
        "def gentle_contract_sr(ranges, conf, round_num, center_design=None):\n",
        "    if center_design is None:\n",
        "        return ranges\n",
        "    base = {1:0.24, 2:0.20, 3:0.18}.get(round_num, 0.18)\n",
        "    frac = max(0.08, min(0.25, base * (0.9 + 0.4*float(conf))))\n",
        "    return shrink_around(center_design, ranges, frac=frac)\n",
        "\n",
        "W_SINGLE = {\"gain_dB\":1.0, \"ugbw_MHz\":1.0, \"phase_margin_deg\":1.0, \"power_mW\":1.0}\n",
        "\n",
        "SR_ACTOR_MEM, SR_CRITIC_MEM = [], []\n",
        "history_sr = []\n",
        "best_sr = None  # decouple from AC best to explore its own basin\n",
        "\n",
        "for r in range(1, 3+1):\n",
        "    if r == 1:\n",
        "        sysS, usrS = actor_first_round_prompt(CALIB, targets=BOUND, eps=EPS,\n",
        "                                              actor_memory=SR_ACTOR_MEM, critic_memory=SR_CRITIC_MEM)\n",
        "    else:\n",
        "        sysS, usrS = actor_feedback_prompt(\n",
        "            critic_conf=history_sr[-1].get(\"critic_conf\", 0.5),\n",
        "            critic_memo=history_sr[-1].get(\"critic_memo\",\"\"),\n",
        "            top5_points=history_sr[-1][\"top5\"], last_best=best_sr,\n",
        "            history_ranges=[h[\"critic_ranges\"] for h in history_sr],\n",
        "            targets=BOUND, eps=EPS,\n",
        "            actor_memory=SR_ACTOR_MEM, critic_memory=SR_CRITIC_MEM\n",
        "        )\n",
        "\n",
        "    outS = ask_self_actor([{\"role\":\"system\",\"content\":sysS},{\"role\":\"user\",\"content\":usrS}], max_new_tokens=96)\n",
        "    try:\n",
        "        actor_s = find_json_block(outS)\n",
        "    except:\n",
        "        actor_s = {\"ranges\": (history_sr[-1][\"critic_ranges\"] if r>1 else {k:list(v) for k,v in PDK[\"vars\"].items()}),\n",
        "                   \"notes\": f\"fallback-self-actor{r}\"}\n",
        "    r_raw = actor_s.get(\"ranges\", {})\n",
        "    r_val,_ = validate_ranges(r_raw)\n",
        "\n",
        "    sysSR, usrSR = critic_audit_prompt({\"ranges\":r_val, \"notes\": actor_s.get(\"notes\",\"\")}, \"OK\",\n",
        "                                       feedback_top5=(history_sr[-1][\"top5\"] if r>1 else None),\n",
        "                                       last_best=(best_sr if r>1 else None),\n",
        "                                       critic_memory=SR_CRITIC_MEM)\n",
        "    outSR = ask_self_critic([{\"role\":\"system\",\"content\":sysSR},{\"role\":\"user\",\"content\":usrSR}], max_new_tokens=96)\n",
        "    try:\n",
        "        critic_s = find_json_block(outSR)\n",
        "    except:\n",
        "        critic_s = {\"ranges\": r_val, \"confidence\": 0.5 + 0.05*(r-1), \"memo\": f\"fallback-self-critic{r}\"}\n",
        "\n",
        "    r_final,_ = validate_ranges(critic_s.get(\"ranges\", r_val))\n",
        "    center_sr = best_sr[\"design\"] if best_sr and best_sr.get(\"design\") else None\n",
        "    r_use = gentle_contract_sr(r_final, critic_s.get(\"confidence\",0.5), r, center_design=center_sr)\n",
        "    r_use,_ = validate_ranges(r_use)\n",
        "    # small global blend to avoid dead-zone collapse\n",
        "    r_use = mix_ranges(r_use, PDK[\"vars\"], mix=0.18)\n",
        "    r_use,_ = validate_ranges(r_use)\n",
        "\n",
        "    seed_off = 1000*r + 73\n",
        "    best_r, top5_r, all_r = cem_search(\n",
        "        r_use, weights=W_SINGLE, best_so_far=best_sr, total_budget=100,\n",
        "        round_num=r, iters=3, pop=36, global_mix=0.30, seed_offset=seed_off\n",
        "    )\n",
        "\n",
        "    if (best_sr is None) or (best_r[\"fom\"] > best_sr[\"fom\"]):\n",
        "        best_sr = best_r\n",
        "\n",
        "    # lightweight reflections\n",
        "    try:\n",
        "        sysAR, usrAR = actor_reflect_prompt(r, critic_s.get(\"memo\",\"\"), best_r, top5_r, W_SINGLE, r_use)\n",
        "        outAR = ask_self_actor([{\"role\":\"system\",\"content\":sysAR},{\"role\":\"user\",\"content\":usrAR}], temperature=0.2, greedy=False, max_new_tokens=96)\n",
        "        arj = find_json_block(outAR)\n",
        "        SR_ACTOR_MEM.append(arj.get(\"reflection\",\"\") + \" | \" + \"; \".join(arj.get(\"rules\",[])[:3]))\n",
        "        SR_ACTOR_MEM[:] = SR_ACTOR_MEM[-6:]\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    try:\n",
        "        sysCR, usrCR = critic_reflect_prompt(r, best_r, all_r, W_SINGLE, r_use)\n",
        "        outCR = ask_self_critic([{\"role\":\"system\",\"content\":sysCR},{\"role\":\"user\",\"content\":usrCR}], max_new_tokens=96)\n",
        "        crj = find_json_block(outCR)\n",
        "        SR_CRITIC_MEM.append(crj.get(\"memo\",\"\") + \" | \" + \"; \".join(crj.get(\"guardrails\",[])[:3]))\n",
        "        SR_CRITIC_MEM[:] = SR_CRITIC_MEM[-6:]\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    history_sr.append({\n",
        "        \"round\": r,\n",
        "        \"actor_ranges\": r_val, \"critic_ranges\": r_use,\n",
        "        \"critic_conf\": critic_s.get(\"confidence\", 0.5),\n",
        "        \"critic_memo\": critic_s.get(\"memo\",\"\"),\n",
        "        \"best\": best_r, \"top5\": top5_r, \"all\": all_r,\n",
        "        \"actor_mem\": list(SR_ACTOR_MEM), \"critic_mem\": list(SR_CRITIC_MEM)\n",
        "    })\n",
        "    print(f\"[SR R{r}] FoM={best_r['fom']:+.8f} | metrics={best_r['metrics']} | design={best_r['design']}\")\n",
        "\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "eFt2ADUXSn6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 15 — Results table (Single‑LLM)\n",
        "import pandas as pd\n",
        "rows_sr=[]\n",
        "for h in history_sr:\n",
        "    b=h[\"best\"]; m=b[\"metrics\"]; d=b[\"design\"]\n",
        "    if m is not None and d is not None:\n",
        "        rows_sr.append({\n",
        "            \"Round\":h[\"round\"], \"FoM\":b[\"fom\"], \"gap_to_zero\":-b[\"fom\"],\n",
        "            \"gain_dB\":m[\"gain_dB\"], \"ugbw_MHz\":m[\"ugbw_MHz\"], \"PM_deg\":m[\"phase_margin_deg\"], \"power_mW\":m[\"power_mW\"],\n",
        "            \"Wn_um\":d[\"Wn_um\"], \"Wp_um\":d[\"Wp_um\"], \"W2n_um\":d[\"W2n_um\"], \"W2p_um\":d[\"W2p_um\"],\n",
        "            \"L_um\":d[\"L_um\"], \"Ib_mA\":d[\"Ib_mA\"], \"Ccomp_pF\":d[\"Ccomp_pF\"], \"Rz_ohm\":d[\"Rz_ohm\"],\n",
        "            \"Self_conf\":round(h.get(\"critic_conf\",0.5), 2)\n",
        "        })\n",
        "df_self = pd.DataFrame(rows_sr).round(4)\n",
        "df_self\n"
      ],
      "metadata": {
        "id": "Qqtl9JlwSn20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final plot — EMA mean with SE shading (AC vs Single-LLM)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def traces_from_history(hist):\n",
        "    return [np.array([rec[\"fom\"] for rec in h[\"all\"]]) for h in hist]\n",
        "\n",
        "def ewm_mean_se(y, alpha=0.15):\n",
        "    y = np.asarray(y, dtype=float)\n",
        "    n = len(y)\n",
        "    mu, var, se = np.zeros(n), np.zeros(n), np.zeros(n)\n",
        "    mu_prev = var_prev = 0.0\n",
        "    sum_w = sum_w2 = 0.0\n",
        "    one_ma = 1.0 - alpha\n",
        "    for t in range(n):\n",
        "        x = y[t]\n",
        "        sum_w  = one_ma * sum_w  + alpha\n",
        "        sum_w2 = (one_ma**2) * sum_w2 + alpha**2\n",
        "        mu_t   = one_ma * mu_prev + alpha * x\n",
        "        var_t  = one_ma * (var_prev + alpha * (x - mu_prev)**2)\n",
        "        n_eff  = (sum_w**2) / max(sum_w2, 1.0)\n",
        "        mu[t], var[t] = mu_t, var_t\n",
        "        se[t]  = np.sqrt(max(var_t, 0.0)) / np.sqrt(max(n_eff, 1.0))\n",
        "        mu_prev, var_prev = mu_t, var_t\n",
        "    return mu, se\n",
        "\n",
        "cal_color = \"#808080\"\n",
        "ac_line   = \"#003366\"\n",
        "sr_line   = \"#B22222\"\n",
        "ac_fill   = \"#3A8DFF\"\n",
        "sr_fill   = \"#FF7F7F\"\n",
        "\n",
        "calib_foms = np.array([ledro_fom({\"gain_dB\":p[\"metrics\"][\"gain_dB\"],\n",
        "                                  \"ugbw_MHz\":p[\"metrics\"][\"ugbw_MHz\"],\n",
        "                                  \"phase_margin_deg\":clamp_pm_for_scoring(p[\"metrics\"][\"phase_margin_deg\"]),\n",
        "                                  \"power_mW\":p[\"metrics\"][\"power_mW\"]}, b=BOUND) for p in CALIB_POOL])\n",
        "x_cal, post_cal = np.arange(1, len(calib_foms)+1), len(calib_foms)\n",
        "ac_trs, sr_trs = traces_from_history(history), traces_from_history(history_sr)\n",
        "\n",
        "x_ac, x_sr = [], []\n",
        "off = post_cal\n",
        "for t in ac_trs:\n",
        "    xa = off + np.arange(1, len(t)+1)\n",
        "    x_ac.append(xa)\n",
        "    off += len(t)\n",
        "off = post_cal\n",
        "for t in sr_trs:\n",
        "    xs = off + np.arange(1, len(t)+1)\n",
        "    x_sr.append(xs)\n",
        "    off += len(t)\n",
        "\n",
        "x_ac_all = np.concatenate(x_ac) if x_ac else np.array([])\n",
        "y_ac_all = np.concatenate(ac_trs) if ac_trs else np.array([])\n",
        "x_sr_all = np.concatenate(x_sr) if x_sr else np.array([])\n",
        "y_sr_all = np.concatenate(sr_trs) if sr_trs else np.array([])\n",
        "\n",
        "alpha = 0.15\n",
        "mu_ac, se_ac = ewm_mean_se(y_ac_all, alpha) if len(y_ac_all) else ([], [])\n",
        "mu_sr, se_sr = ewm_mean_se(y_sr_all, alpha) if len(y_sr_all) else ([], [])\n",
        "\n",
        "round_x = []\n",
        "cum = post_cal\n",
        "for t in ac_trs:\n",
        "    round_x.append(cum + 1)\n",
        "    cum += len(t)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(11,6))\n",
        "ax.scatter(x_cal, calib_foms, s=25, alpha=0.55, color=cal_color, label=\"Calibration\", zorder=1)\n",
        "if len(x_ac_all):\n",
        "    ax.plot(x_ac_all, mu_ac, color=ac_line, lw=2.8, label=\"Actor–Critic\", zorder=4)\n",
        "    ax.fill_between(x_ac_all, mu_ac - se_ac, mu_ac + se_ac, color=ac_fill, alpha=0.25, linewidth=0, zorder=2)\n",
        "if len(x_sr_all):\n",
        "    ax.plot(x_sr_all, mu_sr, color=sr_line, lw=2.8, label=\"Single-LLM\", zorder=4)\n",
        "    ax.fill_between(x_sr_all, mu_sr - se_sr, mu_sr + se_sr, color=sr_fill, alpha=0.25, linewidth=0, zorder=2)\n",
        "\n",
        "vls = (0, (6,6))\n",
        "for i, rx in enumerate(round_x, 1):\n",
        "    ax.axvline(x=rx, color=\"black\", linestyle=vls, lw=1.4, alpha=0.8, zorder=0)\n",
        "    ax.text(rx + 0.5, 0.06, f\"Round {i}\", rotation=90, va=\"bottom\", ha=\"left\",\n",
        "            transform=ax.get_xaxis_transform(), fontsize=11, color=\"black\")\n",
        "\n",
        "ax.axhline(0.0, ls=\":\", color=\"gray\", lw=1.4, alpha=0.9)\n",
        "ax.set_title(\"FoM per Simulation (SKY130 OTA via ngspice)\", fontsize=20, pad=14)\n",
        "ax.set_xlabel(\"Cumulative simulations\", fontsize=16)\n",
        "ax.set_ylabel(\"FoM (higher is better; ≤ 0 meets cushioned targets)\", fontsize=14)\n",
        "ax.tick_params(axis='both', labelsize=12)\n",
        "ax.grid(True, alpha=0.35)\n",
        "\n",
        "handles, labels = ax.get_legend_handles_labels()\n",
        "keep = {\"Calibration\", \"Actor–Critic\", \"Single-LLM\"}\n",
        "h_final, l_final, seen = [], [], set()\n",
        "for h, l in zip(handles, labels):\n",
        "    if l in keep and l not in seen:\n",
        "        seen.add(l); h_final.append(h); l_final.append(l)\n",
        "ax.legend(h_final, l_final, fontsize=12, frameon=True, loc=\"upper center\",\n",
        "          fancybox=True, framealpha=0.95, ncol=3, handletextpad=1.0, bbox_to_anchor=(0.5, -0.12))\n",
        "\n",
        "fig.tight_layout(rect=[0, 0.04, 1, 1])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "FvsTzwjLSn0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final plot — Running-best FoM with EMA smoothing (AC vs Single-LLM)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def traces_from_history(hist):\n",
        "    return [np.array([rec[\"fom\"] for rec in h[\"all\"]]) for h in hist]\n",
        "\n",
        "def ewm_mean_se(y, alpha=0.15):\n",
        "    y = np.asarray(y, dtype=float)\n",
        "    n = len(y)\n",
        "    mu, var, se = np.zeros(n), np.zeros(n), np.zeros(n)\n",
        "    mu_prev = var_prev = 0.0\n",
        "    sum_w = sum_w2 = 0.0\n",
        "    one_ma = 1.0 - alpha\n",
        "    for t in range(n):\n",
        "        x = y[t]\n",
        "        sum_w  = one_ma * sum_w  + alpha\n",
        "        sum_w2 = (one_ma**2) * sum_w2 + alpha**2\n",
        "        mu_t   = one_ma * mu_prev + alpha * x\n",
        "        var_t  = one_ma * (var_prev + alpha * (x - mu_prev)**2)\n",
        "        n_eff  = (sum_w**2) / max(sum_w2, 1.0e-12)\n",
        "        mu[t], var[t] = mu_t, var_t\n",
        "        se[t]  = np.sqrt(max(var_t, 0.0)) / np.sqrt(max(n_eff, 1.0))\n",
        "        mu_prev, var_prev = mu_t, var_t\n",
        "    return mu, se\n",
        "\n",
        "def running_best(y):\n",
        "    y = np.asarray(y, dtype=float)\n",
        "    if y.size == 0:\n",
        "        return y\n",
        "    return np.maximum.accumulate(y)\n",
        "\n",
        "# Colors / styles\n",
        "cal_color = \"#808080\"\n",
        "ac_line   = \"#003366\"  # Actor–Critic (blue)\n",
        "sr_line   = \"#B22222\"  # Single-LLM (red)\n",
        "ac_fill   = \"#3A8DFF\"\n",
        "sr_fill   = \"#FF7F7F\"\n",
        "\n",
        "# Calibration FoMs\n",
        "calib_foms = np.array([\n",
        "    ledro_fom({\n",
        "        \"gain_dB\": p[\"metrics\"][\"gain_dB\"],\n",
        "        \"ugbw_MHz\": p[\"metrics\"][\"ugbw_MHz\"],\n",
        "        \"phase_margin_deg\": clamp_pm_for_scoring(p[\"metrics\"][\"phase_margin_deg\"]),\n",
        "        \"power_mW\": p[\"metrics\"][\"power_mW\"]\n",
        "    }, b=BOUND) for p in CALIB_POOL\n",
        "])\n",
        "x_cal, post_cal = np.arange(1, len(calib_foms)+1), len(calib_foms)\n",
        "\n",
        "# Per-simulation FoMs (all evaluations) pulled from history\n",
        "ac_trs, sr_trs = traces_from_history(history), traces_from_history(history_sr)\n",
        "\n",
        "# Build x-axes that continue after calibration\n",
        "x_ac, x_sr = [], []\n",
        "off = post_cal\n",
        "for t in ac_trs:\n",
        "    xa = off + np.arange(1, len(t)+1)\n",
        "    x_ac.append(xa)\n",
        "    off += len(t)\n",
        "off = post_cal\n",
        "for t in sr_trs:\n",
        "    xs = off + np.arange(1, len(t)+1)\n",
        "    x_sr.append(xs)\n",
        "    off += len(t)\n",
        "\n",
        "# Flatten\n",
        "x_ac_all = np.concatenate(x_ac) if x_ac else np.array([])\n",
        "y_ac_all = np.concatenate(ac_trs) if ac_trs else np.array([])\n",
        "x_sr_all = np.concatenate(x_sr) if x_sr else np.array([])\n",
        "y_sr_all = np.concatenate(sr_trs) if sr_trs else np.array([])\n",
        "\n",
        "# Use running-best before smoothing\n",
        "alpha = 0.15\n",
        "y_ac_all_best = running_best(y_ac_all)\n",
        "y_sr_all_best = running_best(y_sr_all)\n",
        "\n",
        "mu_ac, se_ac = ewm_mean_se(y_ac_all_best, alpha) if len(y_ac_all_best) else ([], [])\n",
        "mu_sr, se_sr = ewm_mean_se(y_sr_all_best, alpha) if len(y_sr_all_best) else ([], [])\n",
        "\n",
        "# Round markers based on AC round boundaries\n",
        "round_x = []\n",
        "cum = post_cal\n",
        "for t in ac_trs:\n",
        "    round_x.append(cum + 1)\n",
        "    cum += len(t)\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots(figsize=(11,6))\n",
        "ax.scatter(x_cal, calib_foms, s=25, alpha=0.55, color=cal_color, label=\"Calibration\", zorder=1)\n",
        "\n",
        "if len(x_ac_all):\n",
        "    ax.plot(x_ac_all, mu_ac, color=ac_line, lw=2.8, label=\"Actor–Critic\", zorder=4)\n",
        "    ax.fill_between(x_ac_all, mu_ac - se_ac, mu_ac + se_ac, color=ac_fill, alpha=0.25, linewidth=0, zorder=2)\n",
        "if len(x_sr_all):\n",
        "    ax.plot(x_sr_all, mu_sr, color=sr_line, lw=2.8, label=\"Single-LLM\", zorder=4)\n",
        "    ax.fill_between(x_sr_all, mu_sr - se_sr, mu_sr + se_sr, color=sr_fill, alpha=0.25, linewidth=0, zorder=2)\n",
        "\n",
        "vls = (0, (6,6))\n",
        "for i, rx in enumerate(round_x, 1):\n",
        "    ax.axvline(x=rx, color=\"black\", linestyle=vls, lw=1.4, alpha=0.8, zorder=0)\n",
        "    ax.text(rx + 0.5, 0.06, f\"Round {i}\", rotation=90, va=\"bottom\", ha=\"left\",\n",
        "            transform=ax.get_xaxis_transform(), fontsize=11, color=\"black\")\n",
        "\n",
        "ax.axhline(0.0, ls=\":\", color=\"gray\", lw=1.4, alpha=0.9)\n",
        "ax.set_title(\"Running-best FoM per Simulation (SKY130 OTA via ngspice)\", fontsize=20, pad=14)\n",
        "ax.set_xlabel(\"Cumulative simulations\", fontsize=16)\n",
        "ax.set_ylabel(\"FoM (higher is better; ≤ 0 meets cushioned targets)\", fontsize=14)\n",
        "ax.tick_params(axis='both', labelsize=12)\n",
        "ax.grid(True, alpha=0.35)\n",
        "\n",
        "handles, labels = ax.get_legend_handles_labels()\n",
        "keep = {\"Calibration\", \"Actor–Critic\", \"Single-LLM\"}\n",
        "h_final, l_final, seen = [], [], set()\n",
        "for h, l in zip(handles, labels):\n",
        "    if l in keep and l not in seen:\n",
        "        seen.add(l); h_final.append(h); l_final.append(l)\n",
        "ax.legend(h_final, l_final, fontsize=12, frameon=True, loc=\"upper center\",\n",
        "          fancybox=True, framealpha=0.95, ncol=3, handletextpad=1.0, bbox_to_anchor=(0.5, -0.12))\n",
        "\n",
        "fig.tight_layout(rect=[0, 0.04, 1, 1])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GJgu_iBoSnyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "08KJDojmPWWq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNtu+sfiTMPobPD5AcMmoto"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}